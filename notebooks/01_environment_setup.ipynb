{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Environment Setup\n",
    "\n",
    "This notebook verifies your RunPod GPU environment and installs all required dependencies.\n",
    "\n",
    "**Run this notebook first before any experiments.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. System Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GPU Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: CUDA not available! Experiments will be slow on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install Dependencies\n",
    "\n",
    "Run this cell to install all required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!pip install -q flwr>=1.5.0 torch>=2.0.0 torchvision>=0.15.0 numpy>=1.24.0 pandas>=2.0.0 matplotlib>=3.7.0 seaborn>=0.12.0 scikit-learn>=1.3.0 pyyaml>=6.0 tqdm>=4.65.0\n",
    "print(\"Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clone Repository (if not already done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run if you need to clone the repo\n",
    "# !git clone https://github.com/YOUR_USERNAME/multimodal-fl-security.git\n",
    "# %cd multimodal-fl-security"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Setup Project Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Navigate to project root if in notebooks folder\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "PROJECT_ROOT = os.getcwd()\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validate Project Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test core imports\n",
    "try:\n",
    "    from src.attacks import get_attack\n",
    "    from src.defenses import get_defense\n",
    "    from src.models.simple_cnn import create_model\n",
    "    from src.utils.data_loader import load_mnist, get_client_data\n",
    "    from src.utils.metrics import evaluate_model\n",
    "    print(\"✓ All project imports successful!\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ Import error: {e}\")\n",
    "    print(\"Make sure you're in the project root directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test experiment runner import\n",
    "try:\n",
    "    from experiments.run_experiments import ExperimentConfig, ExperimentRunner\n",
    "    print(\"✓ Experiment runner imports successful!\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ Import error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Quick GPU Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick GPU tensor test\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    x = torch.randn(1000, 1000, device=device)\n",
    "    y = torch.mm(x, x)\n",
    "    print(f\"✓ GPU tensor operation successful!\")\n",
    "    print(f\"  Result shape: {y.shape}\")\n",
    "    del x, y\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"Skipping GPU test (CUDA not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✓ Environment Ready!\n",
    "\n",
    "If all checks passed, proceed to **02_dataset_exploration.ipynb**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
